{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3aa3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\Documents\\Programming\\ML\\LEGO_StableDiffusion\\Preprocessing\\BLIP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'BLIP' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/salesforce/BLIP\n",
    "%cd BLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3674bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'BLIP'\n",
      "c:\\Users\\micha\\Documents\\Programming\\ML\\LEGO_StableDiffusion\\Preprocessing\\BLIP\n"
     ]
    }
   ],
   "source": [
    "#if directory already exists:\n",
    "%cd BLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86b5958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.15.0 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: timm==0.4.12 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (0.4.12)\n",
      "Requirement already satisfied: fairscale==0.4.4 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (0.4.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (0.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (1.23.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (21.3)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (0.0.53)\n",
      "Requirement already satisfied: filelock in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (3.8.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (0.11.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from transformers==4.15.0) (6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from timm==0.4.12) (0.14.0)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from timm==0.4.12) (1.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from packaging>=20.0->transformers==4.15.0) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from tqdm>=4.27->transformers==4.15.0) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests->transformers==4.15.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests->transformers==4.15.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests->transformers==4.15.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests->transformers==4.15.0) (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from sacremoses->transformers==4.15.0) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from sacremoses->transformers==4.15.0) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from sacremoses->transformers==4.15.0) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\micha\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from torchvision->timm==0.4.12) (9.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers==4.15.0 timm==0.4.12 fairscale==0.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5f732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03674325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def load_demo_image(image_size,device, path):\n",
    "    raw_image = Image.open(rf\"{path}\").convert('RGB')    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size,image_size),interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "        ]) \n",
    "    image = transform(raw_image).unsqueeze(0).to(device)   \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7052cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['av-emotion-recognition',\n",
       " 'databases',\n",
       " 'ECG_denoising',\n",
       " 'LEGO_StableDiffusion',\n",
       " 'Multimodal-Emotion-Recognition',\n",
       " 'regression.docx',\n",
       " 'trial_env',\n",
       " 'video-emotion-detection']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "062ab567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from models.blip import blip_decoder\n",
    "\n",
    "def generate_captioning(path):\n",
    "    names = os.listdir(path)\n",
    "    image_size = 384\n",
    "    model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth'\n",
    "\n",
    "    model = blip_decoder(pretrained=model_url, image_size=image_size, vit='base')\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for name in names:\n",
    "        try:\n",
    "            image = load_demo_image(image_size=image_size, device=device, path=f\"{path}/{name}\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                caption = model.generate(image, sample=True, top_p=0.9, max_length=20, min_length=5) \n",
    "                with open(\"../Scraped_images/metadata.jsonl\", \"a+\") as f:\n",
    "                    line = f'\"file_name\": \"{name}\", \"text\": \"{caption[0]}\"'\n",
    "                    shutil.copy(f\"{path}/{name}\", rf\"..\\Scraped_images\\{name}\")\n",
    "                    f.write(\"{\"+line+\"}\\n\")\n",
    "        except:\n",
    "            print(\"Error\", name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d43be827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape position embedding from 196 to 576\n",
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\n"
     ]
    }
   ],
   "source": [
    "generate_captioning(\"../../../databases/Lego_db_all_newest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7a974a0e52d53bd8e5b857fb025e94527698489ede518bb5924584f859bf235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
